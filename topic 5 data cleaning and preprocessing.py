# -*- coding: utf-8 -*-
"""Topic 5 Data Cleaning & Preprocessing - Dinny Meilinda Sari.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XyR68Ho6PNgO45KDSYP6GHB1NVH4onII

## Telco Customer Churn - Data Cleaning & Preprocessing

<img src="https://www.cleartouch.in/wp-content/uploads/2022/11/Customer-Churn.png" width="600"/>

Dalam mini project ini, aku melakukan proses pembersihan dan persiapan data menggunakan dataset Telco Customer Churn. Fokus utamanya adalah untuk memastikan data siap digunakan pada tahap analisis atau pemodelan machine learning. Beberapa hal penting yang dikerjakan:


**Langkah-langkah yang dilakukan:**

1.   Missing Values Checking

2.   Categorical Data Encoding

3.   Anomalies and Outlier Handling
"""

# Commented out IPython magic to ensure Python compatibility.
#importing library
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

"""[↑] Di tahap ini, kita memanggil library (alat bantu) yang akan dipakai selama analisis. Misalnya, `pandas` untuk mengolah data, *numpy* untuk perhitungan, serta `seaborn` dan `matplotlib` untuk membuat grafik."""

#import data CSV from google drive
from google.colab import drive
drive.mount('/content/gdrive')

"""[↑]  Karena file dataset-nya ada di Google Drive, kita perlu "menghubungkan" Google Colab dengan akun Drive agar bisa mengakses file tersebut."""

#read CSV file from google drive with url
url = 'https://drive.google.com/file/d/14MJW9XVkQwcBG_TNfwgKW7pOL38sci1X/view?usp=sharing'
path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]
df = pd.read_csv(path)

"""[↑] Kita ambil link file dari *Google Drive *dan ubah ke format yang bisa dibaca oleh *Python*, lalu gunakan pandas untuk membaca file CSV menjadi *dataframe* (tabel data yang bisa dianalisis)."""

#menampilkan/melihat data 5 teratas
df.head()

"""[↑] Untuk memastikan file berhasil dibaca, kita tampilkan 5 baris data teratas menggunakan `df.head()`. Ini membantu kita melihat isi dan struktur awal dari dataset.

### 1. Missing Values Checking

Langkah pertama adalah mengecek apakah ada data yang hilang atau kosong di setiap kolom. Hal ini penting karena data yang tidak lengkap bisa membuat hasil analisis menjadi bias atau tidak akurat. Jika ditemukan, nilai kosong tersebut akan dibersihkan atau diisi dengan cara yang sesuai.
"""

#untuk mengetahui informasi dari dataset seperti variabel, tipe data, dll
df.info()

"""- Jumlah data: **7.043 baris, 25 kolom**

- **Tidak ada missing values** (semua kolom lengkap)

- Tipe data: kombinasi dari `object, int, float, bool`

- Kolom `TotalCharges` masih bertipe `object`, perlu dicek/konversi
"""

#cek missing values di dataset
print(df.isnull().sum())

"""[↑] Menampilkan jumlah data kosong (missing) di tiap kolom.

Hasil: Semua kolom bernilai 0, artinya **tidak ada data kosong**.
"""

#cek persentase missing values di setiap kolom
df.isnull().mean()

"""[↑] Menampilkan persentase data kosong per kolom (dalam format desimal).

Hasil: Semua 0.0, memperkuat kesimpulan bahwa **tidak ada missing values**.

Hasil pengecekan menunjukkan **tidak ada missing values** di dataset, jadi tidak perlu melakukan penghapusan atau imputasi data kosong.

Kita **bisa lewatin** tahap `dropna()` dan `fillna()` karena tidak diperlukan untuk data ini.

### 2. Categorical Data Encoding

Banyak kolom di dataset ini berisi data kategori (seperti *gender, Contract, dan PaymentMethod* ), yang perlu diubah ke bentuk angka agar bisa diproses oleh algoritma machine learning. Proses ini disebut **encoding**, dan dilakukan agar komputer bisa memahami dan mengolah data kategori tersebut dengan benar.

Tujuan:
Mengubah data kategorikal yang hanya punya 2 nilai unik (misalnya Yes/No, Male/Female) menjadi angka 0 dan 1.

Contoh kolom:

**gender** → `Male, Female`

**Partner, Dependents, Churn, PaperlessBilling** → `Yes, No`


---

Cek dulu kolom-kolom mana yang hanya punya 2 nilai:
"""

#Lihat dulu jumlah nilai unik di semua kolom
df.nunique()

df['InternetService'].unique()

df['MultipleLines'].value_counts()

"""Ada beberapa kolom yang punya 2 nilai unik:

*gender, Partner, Dependents, PhoneService, PaperlessBilling, Churn*

Berarti kolom ini bisa kita ubah pakai **`Label Encoding`**.


1. Label Encoding
"""

#ubah teks menjadi angka (Yes/No jadi 1/0, Male/Female jadi 1/0)
df['gender'] = df['gender'].map({'Female': 0, 'Male': 1})
df['Partner'] = df['Partner'].map({'No': 0, 'Yes': 1})
df['Dependents'] = df['Dependents'].map({'No': 0, 'Yes': 1})
df['PhoneService'] = df['PhoneService'].map({'No': 0, 'Yes': 1})
df['PaperlessBilling'] = df['PaperlessBilling'].map({'No': 0, 'Yes': 1})
df['Churn'] = df['Churn'].map({'No': 0, 'Yes': 1})

"""2. One-Hot Encoding (Untuk kolom dengan banyak kategori)

Tujuannya: kalau satu kolom punya lebih dari 2 kategori, kita ubah jadi beberapa kolom baru yang isinya 0/1 (bentuk biner).

Misalnya kolom-kolom ini:

- InternetService → DSL, Fiber optic, No

- Contract → Month-to-month, One year, Two year

- PaymentMethod → banyak pilihan (4+)

- MultipleLines, OnlineSecurity, dll.

---

Pakai pd.get_dummies() untuk otomatis mengubah:
"""

# Reload the original dataframe to revert the changes from previous executions
url = 'https://drive.google.com/file/d/14MJW9XVkQwcBG_TNfwgKW7pOL38sci1X/view?usp=sharing'
path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]
df = pd.read_csv(path)

# Apply Label Encoding
df['gender'] = df['gender'].map({'Female': 0, 'Male': 1})
df['Partner'] = df['Partner'].map({'No': 0, 'Yes': 1})
df['Dependents'] = df['Dependents'].map({'No': 0, 'Yes': 1})
df['PhoneService'] = df['PhoneService'].map({'No': 0, 'Yes': 1})
df['PaperlessBilling'] = df['PaperlessBilling'].map({'No': 0, 'Yes': 1})
df['Churn'] = df['Churn'].map({'No': 0, 'Yes': 1})

# Apply One-Hot Encoding
df = pd.get_dummies(df, columns=['InternetService', 'Contract', 'PaymentMethod', 'MultipleLines'], drop_first=True, dtype=int)

"""Melihat hasil Label Encoding"""

df[['gender', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn']].head()

"""Melihat hasil One-Hot Encoding"""

# Lihat semua kolom yang hasil encode dari MultipleLines, PaymentMethod, dst
df.columns[df.columns.str.contains('MultipleLines|PaymentMethod|Contract')]

df.filter(like='InternetService').head()
df.filter(like='Contract').head()
df.filter(like='PaymentMethod').head()

"""### 3. Anomalies and Outlier Handling

Outlier adalah data yang nilainya jauh berbeda dari kebanyakan data lain.
Misalnya, mayoritas pelanggan bayar Rp70.000–200.000 per bulan, tapi ada satu yang Rp1.000.000 -> ini outlier.

Anomali adalah data yang tidak wajar atau mencurigakan. Bisa jadi kesalahan input, misalnya:

TotalCharges = 0 padahal MonthlyCharges = 80 dan tenure = 12.

---

1. Cek Kolom Numerik Dulu
"""

df.describe()

"""Cek kolom:
MonthlyCharges, TotalCharges, tenure

Kalau ada nilai min, max yang jauh banget dari median (50%), kemungkinan itu outlier.
"""

sns.boxplot(x=df['MonthlyCharges'])
plt.show()

sns.boxplot(x=df['tenure'])
plt.show()

sns.boxplot(x=df['TotalCharges'])
plt.show()

"""Berdasarkan visualisasi boxplot ini, **tidak ada outlier** ataupun terdeteksi secara visual pada kolom `MonthlyCharges, TotalCharges, maupun Tenure.`

---


#### Kesimpulan Data Cleaning & Preprocessing - Telco Customer Churn

1.   Tidak ada data hilang

Setelah dicek, semua kolom dalam dataset lengkap. Jadi **tidak perlu menghapus** atau mengisi data yang kosong.
2.   Data teks sudah diubah ke angka

- Kolom yang hanya punya 2 pilihan (seperti `gender, Churn, dll.`) diubah jadi 0 dan 1 (**Label Encoding**).

- Kolom dengan banyak pilihan (seperti `InternetService, PaymentMethod, dll`.) diubah jadi beberapa kolom baru dengan nilai True/False (One-Hot Encoding).

3.   Tidak ada outlier yang mengganggu

Dari visualisasi boxplot untuk `tenure, MonthlyCharges, dan TotalCharges`, tidak ada nilai ekstrem mencurigakan, jadi data bisa langsung dipakai.
Dengan begitu, data sudah bersih dan siap digunakan untuk analisis lebih lanjut atau membuat model prediksi churn.
"""